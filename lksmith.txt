OVERALL STRATEGY

The overall strategy for loxx should be to find out what threads are blocked on
what mutexes, and do cycle detection.

===============================================================================
How should mutexes be identified?
===============================================================================
FULL POINTER VALUE
Using the full pointer value guarantees uniqueness, but it takes a full 8
bytes on 64-bit systems.

MANAGED IDENTIFIER
We could easily assign a shorter identifier when the
mutex was is first used or created.  It's important __not__ to rely on
pthread_mutex_init being the only way to initialize mutexes; we should
provide some equivalent of PTHREAD_MUTEX_INITIALIZER.  This shouldn't be too
difficult.

A managed identifier almost certainly requires a table somewhere in memory
mapping between the managed identifier and the mutex pointer value.

===============================================================================
How to represent mutex ordering?
===============================================================================
How should we represent the ordering of mutexes?  That is, the "must be taken
before" relationship between two mutexes.

IMPLICIT LINKED LIST
One way to go would be to maintain an implicit linked list of the proper
ordering of mutexes.  The nodes would be the mutex data structures themselves.
This would have to be a doubly-linked list, since web need to be able to handle
deleting mutexes (there's that nasty pthread_mutex_destroy rearing its ugly head
again.)

This scales to any number of mutexes; however, performance will be extremely
poor after a while if many mutexes are used.  We have to traverse the entire
linked list every time we take a mutex; otherwise we might miss something.

This scheme uses a full pointer value representation of mutexes.

BITFIELD
Using the managed identifier scheme, we can use bitfields to represent which
mutexes (among the universe of mutexes) must come before any given mutex.

This scheme requires 1/8th of a byte per mutex, per mutex in the system.
So if you have 1024 mutexes in total, each mutex will take 128 bytes to store
the "before" information.

The nice thing is that lookup is always O(1)-- a vey nice property to have, if
you're doing a lot of locks and unlocks.  The not-so-nice property is that you
have a whole lot of memory consumption going on.

Assume A, B, and C are mutexes.
If a thread takes A, B, and then C (a->b->c), and then later takes C and then A
(c->a), we want to warn about that.  It is a locking error.

That requires that our ordering detection be transitive.


LOCK RULES
When locking:
* Check if the mutex you are trying to take is in the "before" set of
any of the mutexes 
* each thread puts the locks it already owns into the "before" set of
the lock that it's trying to take.


OPTIMIZATIONS


WORKED EXAMPLE
Part I.
thread 1 owns A and B.
He tries to lock C.
A and B need to go into the "before" set of C.

Part II.
thread 2 owns C.
He tries to lock A.
thread 2 checks to see if C is in the "before" set of A.  It is, so a warning is
issued.
